{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SparkonCloud2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuAvE4JLYB3E",
        "colab_type": "text"
      },
      "source": [
        "# Migrating from Spark to BigQuery via Dataproc\n",
        "### get data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnbycI7eX9qQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Catch up cell. Run if you did not do previous notebooks of this sequence\n",
        "!wget http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L60t_de-YNVC",
        "colab_type": "text"
      },
      "source": [
        "# Copy data to GCS\n",
        "Instead of having the data in HDFS, keep the data in GCS. This will allow us to delete the cluster once we are done (\"job-specific clusters\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l6GAMFJYO8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUCKET=''  # CHANGE\n",
        "!gsutil cp kdd* gs://$BUCKET/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg5GgV9jYUn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil ls gs://$BUCKET/kdd*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxgswHgFYaPq",
        "colab_type": "text"
      },
      "source": [
        "# Reading in data\n",
        "Change any hdfs:// URLs to gs:// URLs. The code remains the same"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sG1AKZlYcHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from pyspark.sql import SparkSession, SQLContext, Row\n",
        "\n",
        "spark = SparkSession.builder.appName(\"kdd\").getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "data_file = \"gs://{}/kddcup.data_10_percent.gz\".format(BUCKET)\n",
        "raw_rdd = sc.textFile(data_file).cache()\n",
        "raw_rdd.take(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjXoy-rSYh3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "csv_rdd = raw_rdd.map(lambda row: row.split(\",\"))\n",
        "parsed_rdd = csv_rdd.map(lambda r: Row(\n",
        "    duration=int(r[0]), \n",
        "    protocol_type=r[1],\n",
        "    service=r[2],\n",
        "    flag=r[3],\n",
        "    src_bytes=int(r[4]),\n",
        "    dst_bytes=int(r[5]),\n",
        "    wrong_fragment=int(r[7]),\n",
        "    urgent=int(r[8]),\n",
        "    hot=int(r[9]),\n",
        "    num_failed_logins=int(r[10]),\n",
        "    num_compromised=int(r[12]),\n",
        "    su_attempted=r[14],\n",
        "    num_root=int(r[15]),\n",
        "    num_file_creations=int(r[16]),\n",
        "    label=r[-1]\n",
        "    )\n",
        ")\n",
        "parsed_rdd.take(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-F3ezt9YkNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sqlContext = SQLContext(sc)\n",
        "df = sqlContext.createDataFrame(parsed_rdd)\n",
        "connections_by_protocol = df.groupBy('protocol_type').count().orderBy('count', ascending=False)\n",
        "connections_by_protocol.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e6CwvAFYnGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.registerTempTable(\"connections\")\n",
        "attack_stats = sqlContext.sql(\"\"\"\n",
        "                           SELECT \n",
        "                             protocol_type, \n",
        "                             CASE label\n",
        "                               WHEN 'normal.' THEN 'no attack'\n",
        "                               ELSE 'attack'\n",
        "                             END AS state,\n",
        "                             COUNT(*) as total_freq,\n",
        "                             ROUND(AVG(src_bytes), 2) as mean_src_bytes,\n",
        "                             ROUND(AVG(dst_bytes), 2) as mean_dst_bytes,\n",
        "                             ROUND(AVG(duration), 2) as mean_duration,\n",
        "                             SUM(num_failed_logins) as total_failed_logins,\n",
        "                             SUM(num_compromised) as total_compromised,\n",
        "                             SUM(num_file_creations) as total_file_creations,\n",
        "                             SUM(su_attempted) as total_root_attempts,\n",
        "                             SUM(num_root) as total_root_acceses\n",
        "                           FROM connections\n",
        "                           GROUP BY protocol_type, state\n",
        "                           ORDER BY 3 DESC\n",
        "                           \"\"\")\n",
        "attack_stats.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruCbHlZ0Yp1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "ax = attack_stats.toPandas().plot.bar(x='protocol_type', subplots=True, figsize=(10,25))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfPMuvboY0Gw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ax[0].get_figure().savefig('report.png');\n",
        "!gsutil rm -rf gs://$BUCKET/sparktobq/\n",
        "!gsutil cp report.png gs://$BUCKET/sparktobq/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIfhFbQDY2-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "connections_by_protocol.write.format(\"csv\").mode(\"overwrite\").save(\"gs://{}/sparktobq/connections_by_protocol\".format(BUCKET)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fo4Zs4LY40C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil ls gs://$BUCKET/sparktobq/**"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
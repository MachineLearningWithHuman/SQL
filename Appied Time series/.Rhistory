typeof(num)
x<-as.integer(num)
x<-as.integer(num)
typeof(x)
comp<- -22-6i
class(comp)
typeof(comp)
x <- 3
y <- x>5
typeof(y)
cha<-"sat"
typeof(cha)
num <- 3
int_num <-as.integer(num)
is.integer(int_num)
x <- TRUE
y <- as.integer(x)
is.integer(y)
x <- FALSE
y <- as.integer(x)
is.integer(y)
com_num <- as.complex(num)
class(com_num)
logic_num <- as.logical(num)
is,logical(logic_num)
is.logical(logic_num)
char_num <- as.array(num)
char_num
mat_num <- as.matrix(num)
mat_num
vec_num <- as.vector(num)
vec_num
data_num <- as.data.frame(num)
data_num
data_num$num
list_num <- as.list(num)
list_num
getwd
getwd()
cat("\014")
setwd("C:/Users/admin/Downloads")
#Implement OLS Regression in R
library(caTools)
#load the data
data <- read.csv("bpd_all.csv")
#verify
str(data)
#see data
head(data)
library(data.table)
data.table(data)
summary(data)
#verify doubts
hist(data$X0.00632)
hist(log10(data$X0.00632))
#verify doubts
hist(data$X0.00632)
hist(log10(data$X0.00632))
hist(data$X4.09)
hist(log10(data$X4.09))
#seed
set.seed(123)
data_split <- sample.split(data)
set.seed(123)
data_split <- sample.split(data)
train <- subset(data,data_split==TRUE)
test <- subset(data, data_split==FALSE)
#model building
model <- lm(X1.1~.,data=train)
summary(model)
model
model$residuals
plot(model$residuals)
plot(model$residuals,model$coefficients)
plot(model$residuals,model$effects)
list(model)
model2 <- lm(X1.1~.X18+X2.31+X6.575,data)
model2 <- lm(X1.1~X18+X2.31+X6.575,data)
summary(model2)
cor(data$X1.1,data$X18)
cat("\014")
#data structure in R
#vector
x <- c(1,3,5,7,8) #atomic vector
typeof(x)
mat <- matrix(1:4, nrow = 2,ncol = 2)
mat
mat2 <- matrix(4:6)
mat2
mat2[1:2,]
mat3=mat2[1:2,]
mat3=cbind(mat2[1:2,])
cbind(mat,mat3)
mat-mat3
mat-1
mat3/2
t(mat3)
diag(4)
#vector
#methods
x <- c(1,2,4,6)
x <- seq(0.5,1,100)
x
x <- seq(0.5,100)
x <- seq(0.5,100,1)
x <- seq(0.5,100,by=0.5)
x ,- seq(0.5,100,length.out = 100)
x <- seq(0.5,100,length.out = 100)
#control statesment
values <- 1:10
if(sample(values,1)<=5)
print(paste("value is less than 5"))
if(sample(values,1)<=5)
print(paste(values,"is less than 5"))
if(sample(values,1)<=5)
print(paste(values,"is less than 5"))
values <- c(1,2,3,4,5)
for(id in 1:5){
print(values[id])
}
check <- function(x) {
if (x > 0) {
result <- "Positive"
} else if (x < 0) {
result <- "Negative"
} else {
result <- "Zero"
}
return(result)
}
check(-9)
x = 1: 4
for (i in x) {
if (i == 2) {
next
}
print(i)
}
val <- 5
repeat {
print(val)
val <- val+1
if (val == 10){
break
}
}
cat("\014")
source("ols.R")
source("ols.R")
frac <- c(0.452, 1.5642, 0.84520)
percentage <- round(frac * 100, digits = 1)
out <- paste(percentage, "%", sep = "")
print(out)
ls()
new.vector <- c(0.8223, 0.02487, 1.62, 0.4)
Percent_add(new.vector
)
Percent_add <- function(frac){
percent <- round(frac * 100, digits = 1)
out <- paste(percent, "%", sep = "%")
return(out)
}
ls()
new.vector <- c(0.8223, 0.02487, 1.62, 0.4)
Percent_add(new.vector
)
cat("\014")
#interval Estimation
#estimate the population parameter from sample/random sample data
library(MASS)
head(survey)
help("survey")
#point estimation of population mean
#sample mean
age.mean <- mean(survey$Age, na.rm = TRUE)
age.mean
age.response = na.omit(survey$Age)
n=length(age.response)
sem=sigma/sqrt(n);
sem
n=length(age.response)
sigma=5.45
sem=sigma/sqrt(n)
sem
E=qnorm(.975)*sem
age.mean + c(-E,E)
install.packages("TeachingDemos")
#instead of this textbook formula
library(TeachingDemos)
z.test(age.response,sd=sigma)
#unknow variance
#sigma=?
SE=sd(age.response)/sqrt(n)
#student-t distribution
E = qt(.975, df=n-1)*SE
E
age.mean + c(-E,E)
t.test(age.response)
sigma=5.45  E=0.8 #95% confidence interval
zstar=qnorm(0.975)
sigma=sigma
E=0.8
Sample_size=zstar^2*sigma^2/E^2
Sample_size
gender.response <- na.omit(survey$Sex)
n=length(gender.response)
k=sum(gender.response=="Female")
pbar=k/n
pbar
SE=sqrt(pbar*(1-pbar)/n)
SE
E=qnorm(.975)*SE
E
pbar + c(-E,E)
sample_size= zstar^2 * p *(1-p)/E^2
sample_size
zstar=qnorm(.975)
p=0.5
E=5/100
sample_size= zstar^2 * p *(1-p)/E^2
sample_size
cat("\014")
xbar= 9900
mu0 = 10000
sigma=120
n=30
z = (xbar - mu0)/(sigma/sqrt(n))
alpha = 0.05
z.alpha=qnorm(1-alpha)
-z.alpha
-z.alpha > z
pval = pnorm(z)
pval
#upper tail
#mu <= mu0   #known variance z-test
z
z.alpha
z.alpha > z
Z=(xbar-mu0)/(sigma/sqrt(n))
mu0=15.4
n=35
xbar=14.8
sigma=2.5
Z=(xbar-mu0)/(sigma/sqrt(n))
z.half.alpha=qnorm(1-alpha/2)
c(-z.half.alpha,z.half.alpha)
pval = 2* pnorm(Z)
pval
t = (xbar-mu0)/(sigma/sqrt(n))
xbar= 9900
mu0 = 10000
sigma=125
n=30
t = (xbar-mu0)/(sigma/sqrt(n))
t.alpha <- qt(1-alpha,df=n-1)
-t.alpha
t.alpha
?pt()
pval = pt(t,df=n-1, lower.tail = FALSE)
pval
pval = pt(t,df=n-1)
pval
t.half.alpha <- qt(1-alpha/2, df=n-1)
c(-t.half.alpha,t.half.alpha)
t
pval=2 *pt(t,df=n-1)
pval
#voted population
bar=85/148
p0=.6
n=148
z=bar-p0/sqrt(p0*(1-p0)/n)
z          #test statistics
bar=85/148
p0=.6
n=148
z=bar-p0/sqrt(p0*(1-p0)/n)
z          #test statistics
#p > p0 p0 hypothesized lower bound p population proportion
#voted population
bar=85/148
p0=.6
n=148
bar=85/148
p0=.6
n=148
z=(bar-p0)/sqrt(p0*(1-p0)/n)
z          #test statistice
z.alpha=qnorm(1-alpha)
-z.alpha
pval=pnorm(z)
pval
cat("")
cat("\014")
mu0=10000
mu =9950
sd=120
se=0.05
n=30
sigma=sd
sem= sigma/sqrt(n)
q= qnorm(alpha,mean = mu0,sd=sem)
q= qnorm(alpha, mu0,sem)
alpha=se
mu0
q= qnorm(alpha, mu0,sem)
q
pnorm(q,mu,sem,lower.tail=FALSE)
q = qnorm(alpha,mu0,sem,lower.tail = FALSE)
q
pnorm(q, mu,sem)
#two tail test mu=mu0
I=(alpha/2,1-alpha/2)
#two tail test mu=mu0
I=c(alpha/2 , 1-alpha/2)
q= qnorm(I,mu0,sem)
q
pnorm(q,mu,sem)
#inference about two populations
#population mean between two matched sample
library(MASS)
immer
#paired t-test
#
t.test(immer$Y1,immer$Y2,paired = TRUE)
hist(immer$Y1)
hist(immer$Y2)
hist(immer$Y1)
hist(immer$Y2)
median(immer$Y1)
median(immer$Y2)
#independent distribution
#unpaired t-test
mtcars$mpg
mtcars$am
?mtcars
mpg.auto =mtcars[L,]$mpg
L = mtcars$am == 0
mpg.auto =mtcars[L,]$mpg
mpg.auto
mpg.manual=mtcars[!L,]$mpg
mpg.manual
t.test(mpg.auto,mpg.manual)
t.test(mpg~am, data=mtcars)
#
quine
table(quine$Eth,quine$Sex)
prop.test(table(quine$Eth,quine$Sex),correct = FALSE)
cat("\014")
#final destination
#goodness of fit
#follows theoritical distributions
#multinomial goodness of fit
#multinomial >>> categorical & discrete classes of non overlapping
#H0:
library(MASS)
head(survey)
str(survey$Smoke)
levels(survey$Smoke)
smoke.freq=table(survey$Smoke)
smoke.freq
#chi-square test
chisq.test(smoke.freq,p=smoke.prob)
#
smoke.prob <- c(0.045,0.795,0.085,0.075)
#chi-square test
chisq.test(smoke.freq,p=smoke.prob)
#your p-value is greater than your significance interval so you are not going to reject
#null hyphothesis
#chi-squared test of independence
#ones probability distribution doesnt affects the others
tbl=table(survey$Smoke,survey$Exer)
tbl
chisq.test(tbl)
cat("\014")
#Time series analysis
#basic matrix,linear...matrix..timeseries....box-jenkins....jags...stan.....
#basic matrix
matrix(3,2,4)
matrix(1:12,3,4)
matrix(1:12,3,4,byrow = TRUE)
dim(matrix(1:12,3,4))
class(matrix(1:12,3,4))
typeof(matrix(1:12,3,4))
x <- as.data.frame(matrix(1:12,3,4))
#addition
a <- matrix(1:6,2,3)
b <- matrix(1:6,3,2)
a*b
a%*%b
b%*%a
a%*%t(a)
#subsettings
a <- matrix(1:;9, nrow = 3, ncol =3)
#subsettings
a <- matrix(1:9, nrow = 3, ncol =3)
a[1:2,]
a
a[,2]
a[c(1,3),c(1,3)]
#diagonal and identity
diag(1,3)
diag(4,3)
diag(1:3,3)
a <- matrix(3,3,3)
a
diag(a) <- 2
a
a <- matrix(1:9,3,3)
I <- diag(3)
a%*%I
a = diag(3,3) + matrix(1,3,3)
a = diag(3,3) + matrix(1,3,3)
inva = solve(a)
inva %*% a
inva
#choleskey decom
inva <- chol2inv(chol(a))
inva %*% a
install.packages("MARSS")
#----------------------------end of matrix algebra---------------------#
#linear regresion in matrix
library(stats)
library(MARSS)
library(datasets)
data("stackloss",package = "datasets")
stackloss
data = stackloss[1:4,]
data
#basic regression
lm(stack.loss~Air.Flow,data=data)
fit <- lm(stack.loss~Air.Flow,data=data)
Z <- model.matrix(fit)
Z
Z[1:4,]
y <- matrix(data$stack.loss, ncol=1)
y
Z<-cbind(1,data$Air.Flow)
z
Z
#solve
solve(t(Z)%*%Z) %*% t(Z) %*% y
fit.multi <- lm(stack.loss~.,data=data)
Z <- model.matrix(fit.multi)
Z[1:4,]
fit.multi
y <- matrix(data$stack.loss, ncol=1)
y
#Z<-cbind(1,data$Air.Flow,)
Z
#Z<-cbind(1,data$Air.Flow,)
Z<-Z[1:4,]
solve(t(Z)%*%Z) %*% t(Z) %*% y
#groups of intercepts
data = cbind(data, reg=rep(c("n","s"),n)[1:n])
#groups of intercepts
data = cbind(data, reg=rep(c("n","s"), n)[1:n])
data
#groups of intercepts
data = cbind(data, reg=rep(c("n","s"), 4)[1:4])
data
fit2 <- lm(stack.loss~ -1+Air.Flow+reg,data=data)
coef(fit2)
Z= model.matrix(fit2)
Z[1:4,]
y=matrix(data$stack.loss,ncol = 1)
Z=z[1:4,]
Z=Z[1:4,]
solve(t(Z)%*%Z)%*%t(Z) %*% y
coef(fit2)
#group of B
#different owner
data = cbind(data, owner=c("s","a"))
data
fit3 <- lm(stack.loss~-1+Air.Flow:owner + reg, data=data)
coef(fit3)
Z[1:4,]
Z= model.matrix(fit3)
Z[1:4,]
y=matrix(data$stack.loss,ncol = 1)
solve(t(Z)%*%Z)%*%t(Z) %*% y
#seasonal effect
#only considering seasonal effect
data = cbind(data,qtr=paste(rep("qtr",n),1:4,sep=""))
#seasonal effect
#only considering seasonal effect
data = cbind(data,qtr=paste(rep("qtr",4),1:4,sep=""))
data
fit_sea <- lm(stack.loss~-1+qtr,data=data)
coef(fit_sea)
fit_c_sea <- lm(stack.loss~qtr,data=data)
coef(fit_c_sea)
Z=model.matrix(fit_sea)
Z[1:4,]
Z=model.matrix(fit_c_sea)
Z[1:4,]
#putting all it in one
fulldata=stackloss
n =nrow(fulldata)
fulldata = cbind(fulldata,owner=rep(c("a","b","c"),n)[1:n],qtr=paste(rep("qtr",n),1:n,sep=""),
reg=rep(c("n","s"),n)[1:n])
fit_full <- lm(stack.loss~-1+qtr+Air.flow:owner:qtr,data=fulldata)
fit_full <- lm(stack.loss~-1+qtr+Air.Flow:owner:qtr,data=fulldata)
Z <- model.matrix(fit_full)
Z[1:n,]
coef(fit_full)
Z<-Z[1:n,]
y=matrix(data$stack.loss,ncol = 1)
solve(t(Z)%*%Z)%*%t(Z) %*% y
cat("\014")
setwd("C:/Users/admin/YouTube/Appied Time series")
cat("\014")
